This repository is growing and will contain all my explorations wrt adversarial perturbations, attacks and robustness. My interest in this field comes from mechanistic interpretability, any code/musings related to the saem with live here.

# Acknowledgements and resources
For adversarial attacks and robustness:
- https://adversarial-ml-tutorial.org/introduction by Zico and Aleksander
- https://proceedings.neurips.cc/paper_files/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf (Adversarial Examples are not Bugs, they are Features)
